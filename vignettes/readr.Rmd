---
title: "Introduction to readr"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Introduction to readr}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, include = FALSE}
library(readr)
knitr::opts_chunk$set(collapse = TRUE, comment = "#>")
```

The key problem that readr solves is __parsing__ a flat file into a tibble. Parsing is the process of taking a text file and turning it into a rectangular tibble where each column is the appropriate part. Parsing takes place in three basic stages:

1.  The flat file is parsed into a rectangular matrix of
    strings.

1.  The type of each column is determined.

1.  Each column of strings is parsed into a vector of a 
    more specific type.

It's easiest to learn how this works in the opposite order Below, you'll learn how the:

1.  __Vector parsers__ turn a character vector in to a 
    more specific type. 

1.  __Column specification__ describes the type of each 
    column and the strategy readr uses to guess types so
    you don't need to supply them all.
    
1.  __Rectangular parsers__ turn a flat file into a 
    matrix of rows and columns.
  
Each `parse_*()` is coupled with a `col_*()` function, which will be used in the process of parsing a complete tibble. 

## Vector parsers

It's easiest to learn the vector parses using `parse_` functions. These all take a character vector and some options. They return a new vector the same length as the old, along with an attribute describing any problems.

### Atomic vectors

`parse_logical()`, `parse_integer()`, `parse_double()`, and `parse_character()` are straightforward parsers that produce the corresponding atomic vector.

```{r}
parse_integer(c("1", "2", "3"))
parse_double(c("1.56", "2.34", "3.56"))
parse_logical(c("true", "false"))
```

By default, readr expects `.` as the decimal mark and `,` as the grouping mark. You can override this default using `locale()`, as described in `vignette("locales")`.

### Flexible numeric parser

`parse_integer()` and `parse_double()` are strict: the input string must be a single number with no leading or trailing characters. `parse_number()` is more flexible: it ignores non-numeric prefixes and suffixes, and knows how to deal with grouping marks. This makes it suitable for reading currencies and percentages:

```{r}
parse_number(c("0%", "10%", "150%"))
parse_number(c("$1,234.5", "$12.45"))
```

### Date/times

readr supports three types of date/time data:

* dates: number of days since 1970-01-01.
* times: number of seconds since midnight.
* datetimes: number of seconds since midnight 1970-01-01.

```{r}
parse_datetime("2010-10-01 21:45")
parse_date("2010-10-01")
parse_time("1:00pm")
```

Each function takes a `format` argument which describes the format of the string. If not specified, it uses a default value:

* `parse_datetime()` recognises
  [ISO8601](https://en.wikipedia.org/wiki/ISO_8601) 
  datetimes.

* `parse_date()` uses the `date_format` specified by
  the `locale()`. The default value is `%AD` which uses
  an automatic date parser that recognises dates of the 
  format `Y-m-d` or `Y/m/d`.
  
* `parse_time()` uses the `time_format` specified by
  the `locale()`. The default value is `%At` which uses
  an automatic time parser that recognises times of the
  form `H:M` optionally followed by seconds and am/pm.
  
In most cases, you will need to supply a `format`, as documented in `parse_datetime()`:

```{r}
parse_datetime("1 January, 2010", "%d %B, %Y")
parse_datetime("02/02/15", "%m/%d/%y")
```

### Factors

When reading a column that has a known set of values, you can read directly into a factor. `parse_factor()` will generate a warning if a value is not in the supplied levels.
 
```{r}
parse_factor(c("a", "b", "a"), levels = c("a", "b", "c"))
parse_factor(c("a", "b", "d"), levels = c("a", "b", "c"))
```

## Column specification

It would be tedious if you had to specify the type of every column when reading a file. Instead readr, uses some heuristics to guess the type of each column. You can access these results yourself using `guess_parser()`:

```{r}
guess_parser(c("a", "b", "c"))
guess_parser(c("1", "2", "3"))
guess_parser(c("1,000", "2,000", "3,000"))
guess_parser(c("2001/10/10"))
```

The guessing policies are described in the documentation for the individual functions. Guesses are fairly strict. For example, we don't guess that currencies are numbers, even though we can parse them:

```{r}
guess_parser("$1,234")
parse_number("$1,234")
``` 

There are two parsers that will never be guessed: `col_skip()` and `col_factor()`. You will always need to supply these explicitly.

You can see the specification that readr would generate for a file by using `spec_csv()`, `spec_tsv()`, and so on.

```{r}
x <- spec_csv(readr_example("my_dates.csv"))
```

For bigger files, you can often make the specification simpler by changing the default column type using `cols_condense()`

```{r}
mtcars_spec <- spec_csv(readr_example("mtcars.csv"))
mtcars_spec

cols_condense(mtcars_spec)
```

When guessing column types, readr selects rows interspersed through-out the file and always includes the first and last row. The default number of rows it selects is 1000. If the column type guess is incorrect, increasing `guess_max` may or may not improve the results.

```{r}
x <- spec_csv(readr_example("my_dates.csv"), guess_max = 1001)
```

The best solution is to manually specify the `col_type`, as described below.

## Rectangular parsers

readr comes with five parsers for rectangular file formats:

* `read_csv()` and `read_csv2()` for csv files
* `read_tsv()` for tabs separated files
* `read_fwf()` for fixed-width files
* `read_log()` for web log files

If readr finds problems with parsing your data, it will emit a warning message.
For example, in our aptly named `my_dates.csv` file, the column type we expected from our data was a column of dates.

```{r}
df1 <- read_csv(readr_example("my_dates.csv"))
```

The data was successfully imported, but we get a warning message about parsing issues.
To view more details about these parsing issues, call `problems()` on your data frame.
This will generate a data frame with information about the parsing problems, with one row per problem.

```{r}
problems(df1)
```

In this example, one of the dates is in an incorrect format.
Since `problems()` gives us the row number from the original file, we can view that area of data in R with a combination of `readr::read_lines()` and `writeLines()`.  

```{r}
problem_area <- problems(df1)$row - 2
writeLines(read_lines(readr_example("my_dates.csv"), skip = problem_area, n_max = 3))
```

We can work around this parsing error by importing the date column as character and converting it to a column of dates, after the fact. Importing as character and using a more specialized package to parse the data post-import, is a common solution to parsing tricky columns. In this case, the lubridate package can parse our column back into dates.

```{r, eval = FALSE}
df1 <- read_csv(readr_example("my_dates.csv"), col_types = list(
  dates = col_character()
))
df1$dates <- lubridate::ymd(df1$dates)
df1[problem_area:(problem_area + 2), ]
#> # A tibble: 3 Ã— 1
#>   dates     
#>   <date>    
#> 1 2020-02-04
#> 2 2022-09-07
#> 3 2022-07-30
```

In general, it's good practice to supply an explicit column specification to readr. It is more work, but it ensures that you get warnings if the data changes in unexpected ways. To be really strict, you can use `stop_for_problems(df1)`. This will throw an error if there are any parsing problems, forcing you to fix those problems before proceeding with the analysis.

To access the full column specification after importing, you can call `spec()` on your data frame. If you want to manually specify the column types, you can start by copying and pasting this code, and then tweaking it to fix the parsing problems.

```{r}
spec(df1)
```

### Available column specifications

The available specifications are: (with string abbreviations in brackets)

* `col_logical()` [l], containing only `T`, `F`, `TRUE` or `FALSE`.
* `col_integer()` [i], integers.
* `col_double()` [d], doubles.
* `col_character()` [c], everything else.
* `col_factor(levels, ordered)` [f], a fixed set of values.
* `col_date(format = "")` [D]: with the locale's `date_format`.
* `col_time(format = "")` [t]: with the locale's `time_format`.
* `col_datetime(format = "")` [T]: ISO8601 date times
* `col_number()` [n], numbers containing the `grouping_mark`
* `col_skip()` [_, -], don't import this column.
* `col_guess()` [?], parse using the "best" type based on the input.

Use the `col_types` argument to override the default choices. There are two ways to use it:

* With a string: `"dc__d"`: read first column as double, second as character,
  skip the next two and read the last column as a double. (There's no way to
  use this form with types that take additional parameters.)
  
* With a (named) list of col objects:

  ```{r, eval = FALSE}
  read_csv("iris.csv", col_types = list(
    Sepal.Length = col_double(),
    Sepal.Width = col_double(),
    Petal.Length = col_double(),
    Petal.Width = col_double(),
    Species = col_factor(c("setosa", "versicolor", "virginica"))
  ))
  ```
    
  Or, with their abbreviations:
    
  ```{r, eval = FALSE}
  read_csv("iris.csv", col_types = list(
    Sepal.Length = "d",
    Sepal.Width = "d",
    Petal.Length = "d",
    Petal.Width = "d",
    Species = col_factor(c("setosa", "versicolor", "virginica"))
  ))
  ```
    
Any omitted columns will be parsed automatically, so the previous call
will lead to the same result as:

```{r, eval = FALSE}
read_csv("iris.csv", col_types = list(
  Species = col_factor(c("setosa", "versicolor", "virginica")))
)
```

You can also set a default type that will be used instead of
relying on the automatic detection for columns you don't specify:

```{r, eval = FALSE}
read_csv("iris.csv", col_types = list(
  Species = col_factor(c("setosa", "versicolor", "virginica")),
  .default = col_double())
)
```

If you only want to read specified columns, use `cols_only()`:

```{r, eval = FALSE}
read_csv("iris.csv", col_types = cols_only(
  Species = col_factor(c("setosa", "versicolor", "virginica")))
)
```

### Output

The output of all these functions is a tibble. Note that characters are never automatically converted to factors (i.e. no more `stringsAsFactors = FALSE`) and column names are left as is, not munged into valid R identifiers (i.e. there is no `check.names = TRUE`). Row names are never set.

Attributes store the column specification (`spec()`) and any parsing problems (`problems()`).
