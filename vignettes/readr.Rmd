---
title: "Introduction to readr"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Introduction to readr}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, include = FALSE}
knitr::opts_chunk$set(collapse = TRUE, comment = "#>")
```

Importing data to R is an important operation to master.
Here, we will review how to use readr's suite of functions to do just that.

We can load the readr package individually with:

```{r}
library(readr)
```

Alternatively, because readr is a core tidyverse package we can also load it, along with the rest of the tidyverse package with:

```{r, eval = FALSE}
library(tidyverse)
```

## Data importing

To import data into R, there are a number of different readr functions to import different types of data files found in the wild:

* `read_csv()`: comma separated values (CSV) files
* `read_tsv()`: tab separated values (TSV) files
* `read_delim()`: general delimited files (including CSV and TSV)
* `read_fwf()`: fixed width files
* `read_table()`: tabular files where columns are separated by white-space.
* `read_log()`: web log files

For delimited files, `read_delim()` will work for both csv and tsv files.
There are certain arguments in `read_delim()` that are so commonly used together, they are offered as defaults.
These include `read_csv()` and `read_tsv()`.

For R users who need `read_delim()` to use ',' as the decimal point and ';' as a field separator, `read_csv2()` offers these as default arguments.
This delimiter is most common in European countries.
Because R is US-centric, the default options for most functions are also US-centric.
However, you can specify your location with the `locale()` function which will make encoding data easier.
We will go into more detail about how `locale()` works later on and how it can help make your code more portable.

## Optional Arguments

Data in the wild often comes with certain idiosyncrasies that can make data importing and cleaning difficult.
The readr functions come with several optional arguments to make data importing easier.
Using these optional arguments at import are a good idea because they can decrease the work needed to wrangle your data after import.

Because these arguments are conserved across functions, we can demonstrate them using `read_csv()`.

### col_types

In general, it's good practice to supply an explicit column specification.
If you don't supply readr with a column specification, it will be guessed for you which by nature of guessing, isn't executed perfectly every time.
To make your data importing more robust, supply a full column specification ensures your data is imported the same way each time.
The available specifications are: (with string abbreviations in brackets)

* `col_logical()` [l], containing only `T`, `F`, `TRUE` or `FALSE`.
* `col_integer()` [i], integers.
* `col_double()` [d], doubles.
* `col_character()` [c], everything else.
* `col_factor(levels, ordered)` [f], a fixed set of values.
* `col_date(format = "")` [D]: with the locale's `date_format`.
* `col_time(format = "")` [t]: with the locale's `time_format`.
* `col_datetime(format = "")` [T]: ISO8601 date times
* `col_number()` [n], numbers containing the `grouping_mark`
* `col_skip()` [_, -], don't import this column.
* `col_guess()` [?], parse using the "best" type based on the input.


```{r, include = FALSE}
df <- tibble::tibble(
  x = c(
    "02/10/2022",
    "02/11/2022",
    "02/12/2022",
    "02/13/2022"
  ),
  y = c(
    "0",
    "2.5",
    "1",
    "0"
  ),
  z = c(
    "low",
    "high",
    "medium",
    "low"
  )
)
my_file <- tempfile("df", fileext = ".csv")
write_csv(df, my_file)
writeLines(read_lines(my_file))
```

Sometimes, you don't yet know what column specification to use, which is why readr packages will guess it for you, if not specified.

```{r}
read_csv(my_file)
```

But as your analysis matures, providing readr with column specification will ensure that you get warnings if the data changes in unexpected ways.
To provide readr functions with column specification, use the `col_types` argument.
You can provide a partial column specification while still importing all the data and the other column types will be guessed.

```{r}
read_csv(
  my_file,
  na = "",
  col_types = cols(
    x = col_date(format = "%m/%d/%Y")
  )
)
```

Once you know what column specifications you need, you can supply readr with a full column specification.

```{r}
read_csv(
  my_file,
  na = "",
  col_types = cols(
    x = col_date(format = "%m/%d/%Y"),
    y = col_double(),
    z = col_factor()
  )
)
```

```{r, include = FALSE}
file.remove(my_file)
```

### na

Your data might contain values that you'd like to encode as `NA`.

```{r}
filepath <- readr_example("interpret-nas.csv")
writeLines(read_lines(filepath))
```

Using this argument with one or more strings will set those values to `NA` at import.

```{r}
read_csv(filepath, na = "-", show_col_types = FALSE)
```

### skip

When importing data, there may be some content at the top of the file that you'd like to ignore.
The file in the following examples has some header information, like when the file was created, that we'd like to ignore.

```{r}
# make this more indicative of junk in csv files
# Date created:
# Created by:
filepath <- readr_example("deaths.csv")
writeLines(read_lines(filepath))
```

Setting the skip argument to skip these rows will import the data cleanly.

```{r}
read_csv(filepath, skip = 2, show_col_types = FALSE)
```

### n_max

To control the number of rows to read in we can use `n_max`.

```{r}
filepath <- readr_example("mini_gap_Europe.csv")
writeLines(read_lines(filepath))
```

Setting `n_max` allows us to limit the rows read in by `read_csv()`.

```{r}
read_csv(filepath, n_max = 3, show_col_types = FALSE)
```

### locale

Understanding the `locale()` option gives you more control over importing data from other countries.
The `locale()` option also includes other information not typically found in `locale()` such as time zones and data encoding.

Here we want to import some data from Norway.
Not only are the dates written in Norwegian but the integer values are formatted with a comma decimal mark.


```{r}
filepath <- readr_example("norway.csv")
writeLines(read_lines(filepath))
```

Specifying the locale and specifying the date format and decimal mark makes this data more portable.

```{r}
read_csv(
  filepath,
  locale = locale("nb", date_format = "%d %B %Y", decimal_mark = ","),
  show_col_types = FALSE
)
```

### trim white space

For data that contains extraneous white spaces, setting `trim_ws = TRUE` can clean up your data at import

```{r}
trim <- tibble::tibble(
  x = c(
    "high ",
    " medium",
    "low",
    "medium low"
  ),
  y = c(10, 10, 10, 15)
)
tfile <- tempfile("trim-whitespace_example-", fileext = ".csv")
write_csv(trim, tfile)
writeLines(read_lines(tfile))
```

Now, the white spaces before and after the text are gone!

```{r}
read_csv(tfile, trim_ws = TRUE, show_col_types = FALSE)
```

```{r, include = FALSE}
file.remove(tfile)
```

### reading in multiple files

You can supply readr with a vector of filenames to import, rather than having to import them separately.

```{r}
read_csv(
  c(
    readr_example("mini_gap_Europe.csv"),
    readr_example("mini_gap_Oceania.csv")
  ),
  show_col_types = FALSE
)
```

### id

<!-- Because readr does not include dplyr in Suggests we can't use dplyr functions to demonstrate id to it's full impact  -->

After importing multiple files, you will probably want to track the file names with the data that came from them.
Often times the file path contains important information that you might want to include, like the date of data collection.
You can use the id option to create a new column that holds this information.

```{r}
mini_gap <- read_csv(
  c(
    readr_example("mini_gap_Europe.csv"),
    readr_example("mini_gap_Oceania.csv")
  ),
  show_col_types = FALSE, id = "filename"
)
```


It's common to need to tinker with the filename to extract the real information you want to track.
In our example below, we want just the basename of the filepath.

```{r}
mini_gap$filename <- basename(mini_gap$filename)
mini_gap
```

We could also do this with dplyr's `mutate()` function.

```{r, eval = FALSE}
dplyr::mutate(mini_gap, filename = basename(filename))
```


### lazy

<!-- https://www.tidyverse.org/blog/2021/11/readr-2-1-0-lazy/#the-advantages-of-lazy-reading -->

<!-- We could make this example a more robust example using filter/mutate but we can't use dplyr functions in readr but lazy could be an article which would allow us to use dplyr functions -->

One of the big improvements that was made with readr edition 2 was lazy reading.
With lazy reading, the data is read on-demand.
Lazy reading is turned off by default so you much turn it on with `lazy = TRUE`.
In this example, only the data that is needed to calculate the mean mpg for a subset of cars, is loaded into R.

```{r, eval = FALSE}
library(dplyr)
read_csv(
  readr_example("mtcars.csv"),
  lazy = TRUE
) %>% 
  filter(hp > 200) %>%
  summarise(mean(mpg))
```

### quote

For textual data that contains quoted text, specifying the quote type can impact how the data is imported.
First, we try reading in this data without specifying the quote type.
The default is `quote = "/""`, so this doesn't work well.

```{r}
read_csv(
  readr_example("funny_quotes.csv"),
  show_col_types = FALSE
)
```

But when we specify the quote type, readr correctly imports our quoted data.

```{r}
read_csv(
  readr_example("funny_quotes.csv"),
  show_col_types = FALSE, quote = "\'"
)
```

## Troubleshooting

Data importing doesn't always go as planned.
If there are parsing problems, readr will generate a data frame of problems.

```{r}
my_nums <- read_csv(
  readr_example("problem_numbers.csv"),
  col_types = cols(
    value = col_integer()
  )
)
```

The first few will be printed out, and you can access them all with `problems()`:

```{r}
problems(my_nums)
```

Getting the data in front of you can help diagnose any problems.
Use `writeLines()` with `read_lines()` and specify the subset of rows you'd like to look at.

```{r}
writeLines(
  read_lines(
    readr_example("problem_numbers.csv"),
    skip = 4,
    n_max = 3
  )
)
```

We can fix our problem by specifying that we want this column to be a column of doubles rather than integers.

```{r}
read_csv(
  readr_example("problem_numbers.csv"),
  col_types = cols(
    value = col_double()
  )
)
```
